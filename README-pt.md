# Rede Neural Totalmente Conectada para ClassificaÃ§Ã£o de EmoÃ§Ãµes (PortuguÃªs)

## VisÃ£o Geral
Este projeto implementa uma rede neural totalmente conectada (FCNN) para classificaÃ§Ã£o de emoÃ§Ãµes em textos em portuguÃªs, utilizando o dataset [Portuguese Tweets](https://huggingface.co/datasets/fpaulino/portuguese-tweets) da Hugging Face. O modelo classifica textos em trÃªs categorias de sentimentos: tristeza, alegria e neutro.

## ğŸ“‘ Ãndice
- [Rede Neural Totalmente Conectada para ClassificaÃ§Ã£o de EmoÃ§Ãµes (PortuguÃªs)](#rede-neural-totalmente-conectada-para-classificaÃ§Ã£o-de-emoÃ§Ãµes-portuguÃªs)
  - [VisÃ£o Geral](#visÃ£o-geral)
  - [ğŸ“‘ Ãndice](#-Ã­ndice)
  - [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto)
  - [ğŸ“Š Conjunto de Dados](#-conjunto-de-dados)
  - [ğŸ” PrÃ©-processamento de Texto](#-prÃ©-processamento-de-texto)
  - [ğŸ§  Arquitetura do Modelo](#-arquitetura-do-modelo)
  - [âš™ï¸ Detalhes do Treinamento](#ï¸-detalhes-do-treinamento)
  - [ğŸš€ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
    - [PrÃ©-requisitos](#prÃ©-requisitos)
    - [Passos](#passos)
  - [ğŸ› ï¸ Uso](#ï¸-uso)
    - [ğŸ“¥ PreparaÃ§Ã£o dos Dados](#-preparaÃ§Ã£o-dos-dados)
    - [ğŸ‹ï¸ Treinar o Modelo](#ï¸-treinar-o-modelo)
    - [ğŸ” Testar o Modelo](#-testar-o-modelo)
  - [ğŸ“ˆ Desempenho](#-desempenho)
  - [ğŸ“‹ Requisitos](#-requisitos)
  - [ğŸ‘¥ Contribuindo](#-contribuindo)
  - [ğŸ“„ LicenÃ§a](#-licenÃ§a)
  - [ğŸ™ Agradecimentos](#-agradecimentos)

## ğŸ“ Estrutura do Projeto
```
fcnn_pt_BR_emotion_classification/
â”‚
â”œâ”€â”€ data/                  # DiretÃ³rio de dados
â”‚   â”œâ”€â”€ train_data.parquet # Dados de treinamento
â”‚   â”œâ”€â”€ test_data.parquet  # Dados de teste
â”‚   â””â”€â”€ validation_data.parquet # Dados de validaÃ§Ã£o
â”‚
â”œâ”€â”€ model/                 # DiretÃ³rio de artefatos do modelo
â”‚   â”œâ”€â”€ fcnn.keras         # Modelo Keras salvo
â”‚   â”œâ”€â”€ label_encoder.joblib # Codificador de rÃ³tulos serializado
â”‚   â””â”€â”€ vectorizer.joblib  # Vetorizador TF-IDF serializado
â”‚
â”œâ”€â”€ utils/                 # MÃ³dulos utilitÃ¡rios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluate_and_save.py # UtilitÃ¡rios para avaliaÃ§Ã£o e salvamento do modelo
â”‚   â”œâ”€â”€ preprocessing.py   # FunÃ§Ãµes de prÃ©-processamento de texto
â”‚   â””â”€â”€ training_plot.py   # UtilitÃ¡rios de visualizaÃ§Ã£o de treinamento
â”‚
â”œâ”€â”€ explore_data.ipynb     # Notebook para AnÃ¡lise ExploratÃ³ria de Dados (EDA)
â”œâ”€â”€ data_preparation.py    # Script para download e prÃ©-processamento de dados
â”œâ”€â”€ model_trainer.py       # Script para treinamento e avaliaÃ§Ã£o do modelo
â”œâ”€â”€ test_model.py          # Script para testar o modelo com novas entradas (a ser criado)
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
```

## ğŸ“Š Conjunto de Dados
Este projeto utiliza o dataset [Portuguese Tweets](https://huggingface.co/datasets/fpaulino/portuguese-tweets) da Hugging Face, que contÃ©m amostras de texto em portuguÃªs rotuladas com trÃªs sentimentos:
- ğŸ˜¢ Tristeza
- ğŸ˜„ Alegria
- ğŸ˜ Neutro

O dataset contÃ©m um grande nÃºmero de tweets rotulados, divididos em conjuntos de treinamento e teste. Uma parte do conjunto de treinamento Ã© separada para validaÃ§Ã£o.

## ğŸ” PrÃ©-processamento de Texto
O pipeline de prÃ©-processamento inclui:
- LematizaÃ§Ã£o: Reduzir palavras Ã  sua forma base usando spaCy (`pt_core_news_md`)
- ConversÃ£o para minÃºsculas: Converter todo o texto para letras minÃºsculas
- RemoÃ§Ã£o de stopwords: Remover palavras comuns em portuguÃªs que carregam pouca informaÃ§Ã£o significativa
- NormalizaÃ§Ã£o de espaÃ§os: Padronizar os espaÃ§os entre palavras

O texto processado Ã© entÃ£o vetorizado usando TF-IDF (Term Frequency-Inverse Document Frequency), que converte o texto em recursos numÃ©ricos com base na importÃ¢ncia das palavras.

## ğŸ§  Arquitetura do Modelo
O modelo Ã© uma rede neural totalmente conectada com a seguinte arquitetura:

![FCNN Architecture Placeholder](https://via.placeholder.com/1192x400?text=Arquitetura+da+FCNN+(3+Classes))

- Camada de entrada: Texto vetorizado com TF-IDF (matriz esparsa convertida para densa)
- Camada oculta 1: 1024 neurÃ´nios com ativaÃ§Ã£o SELU, inicializador `lecun_normal` e regularizaÃ§Ã£o L2 (0.01)
- Camada oculta 2: 512 neurÃ´nios com ativaÃ§Ã£o SELU, inicializador `lecun_normal` e regularizaÃ§Ã£o L2 (0.01)
- Camada oculta 3: 256 neurÃ´nios com ativaÃ§Ã£o SELU, inicializador `lecun_normal` e regularizaÃ§Ã£o L2 (0.01)
- Camada oculta 4: 64 neurÃ´nios com ativaÃ§Ã£o SELU
- Camada de saÃ­da: 3 neurÃ´nios com ativaÃ§Ã£o softmax (um para cada sentimento)

O modelo utiliza a funÃ§Ã£o de ativaÃ§Ã£o SELU (Scaled Exponential Linear Unit), que auxilia nas propriedades de auto-normalizaÃ§Ã£o e pode levar a uma melhor convergÃªncia durante o treinamento.

## âš™ï¸ Detalhes do Treinamento
- FunÃ§Ã£o de perda: Categorical Crossentropy (`CategoricalCrossentropy`)
- Otimizador: Adam
- Taxa de aprendizado: ComeÃ§a em 0.001 com decaimento por etapas (reduzida pela metade a cada 10 Ã©pocas)
- Pesos das classes: Balanceados usando `compute_class_weight` para lidar com o desequilÃ­brio de classes
- Parada antecipada: Monitorada na perda de validaÃ§Ã£o (`val_loss`) com paciÃªncia de 3 Ã©pocas
- Tamanho do lote: 256
- MÃ¡ximo de Ã©pocas: 20

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- Gerenciador de pacotes pip

### Passos
1. Clone o repositÃ³rio:
```bash
git clone https://github.com/yourusername/fcnn_pt_BR_emotion_classification.git # Substitua pela URL correta
cd fcnn_pt_BR_emotion_classification
```

2. Crie e ative um ambiente virtual (opcional, mas recomendado):
```bash
python -m venv venv
source venv/bin/activate  # No Windows, use: venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Baixe o modelo spaCy para portuguÃªs (feito automaticamente em `preprocessing.py`, mas pode ser executado separadamente):
```bash
python -m spacy download pt_core_news_md
```

## ğŸ› ï¸ Uso

### ğŸ“¥ PreparaÃ§Ã£o dos Dados
Baixe e prÃ©-processe o conjunto de dados:
```bash
python data_preparation.py
```
Este script irÃ¡:
- Baixar o dataset Portuguese Tweets da Hugging Face
- Processar os dados de texto (lematizaÃ§Ã£o, remoÃ§Ã£o de stopwords, etc.)
- Salvar os dados processados como arquivos parquet no diretÃ³rio `data/`

### ğŸ‹ï¸ Treinar o Modelo
Treine o modelo FCNN com os dados prÃ©-processados:
```bash
python model_trainer.py
```
Este script irÃ¡:
- Carregar os dados prÃ©-processados
- Aplicar a vetorizaÃ§Ã£o TF-IDF
- Treinar o modelo com a arquitetura e hiperparÃ¢metros especificados
- Exibir grÃ¡ficos de treinamento mostrando as curvas de perda
- Avaliar o modelo no conjunto de teste
- Salvar o modelo treinado em `model/fcnn.keras`

### ğŸ” Testar o Modelo
Teste o modelo treinado com novas entradas de texto (criar `test_model.py`):
```bash
python test_model.py
```
Este script (a ser criado) permitirÃ¡ testar o modelo com frases em portuguÃªs.

## ğŸ“ˆ Desempenho
As mÃ©tricas de desempenho do modelo (acurÃ¡cia, precisÃ£o, recall, F1-score) sÃ£o avaliadas no conjunto de teste e exibidas apÃ³s o treinamento. O desempenho tÃ­pico para esta arquitetura apresenta:

- AcurÃ¡cia geral: ~65-70%
- PrecisÃ£o e recall variam por classe de emoÃ§Ã£o

![Resultados da ClassificaÃ§Ã£o FCNN](model/fcnn_model.png)

A matriz de confusÃ£o ajuda a visualizar quais emoÃ§Ãµes sÃ£o mais frequentemente classificadas incorretamente e quais o modelo prevÃª com maior confianÃ§a.

## ğŸ“‹ Requisitos
- Python 3.8+
- TensorFlow
- scikit-learn
- pandas
- numpy
- spaCy (com o modelo `pt_core_news_md`)
- matplotlib
- joblib
- nltk (para stopwords)
- pyarrow (para leitura de parquet)
- emoji

*(Consulte `requirements.txt` para versÃµes especÃ­ficas)*

## ğŸ‘¥ Contribuindo
ContribuiÃ§Ãµes para melhorar a arquitetura do modelo, o prÃ©-processamento ou adicionar novos recursos sÃ£o bem-vindas! Sinta-se Ã  vontade para enviar um pull request.

1. FaÃ§a um fork do repositÃ³rio
2. Crie sua branch de recurso (`git checkout -b feature/novo-recurso`)
3. FaÃ§a commit das suas alteraÃ§Ãµes (`git commit -m 'Adicionar novo recurso'`)
4. Envie para a branch (`git push origin feature/novo-recurso`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a
[LicenÃ§a MIT](LICENSE)

## ğŸ™ Agradecimentos
- [fpaulino](https://huggingface.co/fpaulino) por fornecer o dataset Portuguese Tweets
- [SpaCy](https://spacy.io/) por utilitÃ¡rios de processamento de linguagem natural
- [TensorFlow](https://www.tensorflow.org/) e [Keras](https://keras.io/) pelo framework de deep learning
- [Scikit-learn](https://scikit-learn.org/) por utilitÃ¡rios de machine learning
- [NLTK](https://www.nltk.org/) por stopwords em portuguÃªs
- [Hugging Face](https://huggingface.co/) pela plataforma de datasets
- [Netron](https://github.com/lutzroeder/netron) pela visualizaÃ§Ã£o de modelos